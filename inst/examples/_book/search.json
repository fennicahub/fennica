[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fennica metadata conversions: statistical monitoring and analysis",
    "section": "",
    "text": "1 Preface chapter\nIt is imperative to underscore that this bookdown project is an evolving work-in-progress, and several additional fields will be incorporated into the dataset as they undergo the rigorous processes of data cleaning and harmonization.\nWithin the FIN-CLARIAH Metadata Harmonization and Analysis work package, we leverage the Finnish national bibliography (FNB) Fennica dataset to develop a harmonized dataset, serving research purposes and laying the groundwork for further infrastructure iterations. The project’s outcomes will be instrumental in supporting the DHL-FI project funded by the Research Council of Finland. The FNB encompasses metadata for over a million documents, including books, newspapers, maps, etc., with records spanning from 1488 to the present. For more details about Fennica, visit The National Finnish Library website.\nCurrently, the bookdown project comprises a few distinct chapters. Notably, the harmonization process has been executed through the establishment of dual pipelines: Complete FNB Pipeline and 1809 to 1917 Period Pipeline These chapters are dedicated to the specific metadata categories.\nHow to reproduce the workflow"
  },
  {
    "objectID": "language.html#description",
    "href": "language.html#description",
    "title": "2  Language",
    "section": "2.1 Description",
    "text": "2.1 Description\nThe polish_languages function is designed to standardize and harmonize language information in a dataset. The process starts by isolating unique language entries, ensuring that each distinct combination of languages is processed only once, which improves efficiency and avoids redundant computations. A MARC reference list of recognized language abbreviations and names is then used to map language codes to their standardized forms. Each language entry is analyzed to identify multiple languages and to detect any unrecognized terms.\nThe entries are standardized by converting them to their recognized forms while eliminating duplicates and filtering out unrecognized languages. Empty cells in the dataset are marked as NA to indicate missing information. Once standardized, all valid languages are aggregated to create a structured data frame. This data frame includes the total number of languages in each entry, a flag (TRUE/FALSE) indicating whether the entry contains multiple languages (including those that are originally coded as mul = Multiple language), the cleaned and harmonized list of languages, and the primary language, which is defined as the first listed language in each entry. The result is a cleaned and standardized dataset that facilitates accurate analysis of multilingual data.\nAdditionally, an error list is generated, consisting of unrecognized language information and the corresponding IDs. This error list helps librarians identify mistakes in the original data and provides context to either correct the errors or explain why certain entries were discarded by the function."
  },
  {
    "objectID": "language.html#complete-dataset-overview",
    "href": "language.html#complete-dataset-overview",
    "title": "2  Language",
    "section": "2.2 Complete Dataset Overview",
    "text": "2.2 Complete Dataset Overview\nUnique languages: 189\nUnique primary languages: 155\n1096354 single-language entries (93.27%)\n79147 multilingual entries , accounting for 6.73% of the total. This includes entries explicitly coded as “mul” (Multiple languages) as well as those with more than one language listed for a single book.\nThere are 930 single-language entries marked as only “Undetermined”, coded as “und”, accounting for (0.08%) of the total.\nThere are 54424 missing values in the dataset,accounting for (4.42%) of the total.\nUnrecognized languages provides details of languages that were discarded, in total: 24. Additionally, the Error list contains ID numbers of entries associated with these discarded languages, intended for librarian review.\nConversions from raw to preprocessed language entries\nNew custom abbreviations can be added in this table.\nDownload language harmonized dataset"
  },
  {
    "objectID": "language.html#subset-analysis-1809-1917",
    "href": "language.html#subset-analysis-1809-1917",
    "title": "2  Language",
    "section": "2.3 Subset Analysis: 1809-1917",
    "text": "2.3 Subset Analysis: 1809-1917\nUnique languages (1809-1917): 56\nUnique primary languages (1809-1917): 40\n61916 single-language entries (93.65%)\n4197 multilingual entries , accounting for 6.35% of the total. This includes entries explicitly coded as “mul” (Multiple languages) as well as those with more than one language listed for a single book.\nThere are 93 entries marked as “Undetermined”.\nThere are 778 missing values in the dataset,accounting for (1.16%) of the total.\nDownload language harmonized dataset (1809-1917)\n\n2.3.1 Top languages for 1809-1917\nNumber of titles assigned with each language (top-10). For a complete list, see accepted languages (1809-1917).\n\n\n\n\nLanguage\nEntries (n)\nFraction (%)\n\n\n\n\nFinnish\n33987\n50.8\n\n\nSwedish\n19997\n29.9\n\n\nGerman\n2212\n3.3\n\n\nRussian\n2123\n3.2\n\n\nFinnish;Swedish\n2072\n3.1\n\n\nLatin\n1879\n2.8\n\n\nFrench\n653\n1\n\n\nEnglish\n417\n0.6\n\n\nSwedish;Latin\n200\n0.3\n\n\nSwedish;Finnish\n187\n0.3\n\n\n\n\nTitle count per language (including multi-language documents; note the log10 scale):"
  },
  {
    "objectID": "publication_time.html#complete-data-overview",
    "href": "publication_time.html#complete-data-overview",
    "title": "3  Publication time",
    "section": "3.1 Complete Data Overview",
    "text": "3.1 Complete Data Overview\nPublication year conversions\nPublication year discarded. 801records are discarded where the publication date is not coded or unknown or contain ambiguous dates, such as non-numeric characters. Error list is for librarians’ use.\nDownload publication time harmonized dataset\nPublication years is available for 1229112 documents (100%). The publication years span is 11-2025.\n\n3.1.1 Title count per decade (log values)\n\n\n\n3.1.2 Publication status summaries\nThу visualization of publication status field enhances understanding of how publication years are recorded. The harmonization process depended on the publication status field due to its nuanced information, which doesn’t always directly signify the start or end of publication.\n\n\n\n\nPublication Status\nEntries (n)\nFraction (%)\n\n\n\n\nSingle known date/probable date\n1099762\n89.4\n\n\nContinuing resource ceased publication\n45120\n3.7\n\n\nPublication date and copyright date\n39650\n3.2\n\n\nContinuing resource currently published\n25331\n2.1\n\n\nQuestionable date\n8393\n0.7\n\n\nInclusive dates of collection\n4735\n0.4\n\n\nReprint/reissue date and original date\n4112\n0.3\n\n\nMultiple dates\n1997\n0.2\n\n\nContinuing resource status unknown\n486\n0\n\n\nDate of distribution etc\n106\n0\n\n\nDetailed date\n82\n0\n\n\nNo attempt to code\n66\n0\n\n\nDates unknown\n27\n0\n\n\nNo dates given; B.C. date involved\n4\n0"
  },
  {
    "objectID": "publication_time.html#subset-analysis-1809-1917",
    "href": "publication_time.html#subset-analysis-1809-1917",
    "title": "3  Publication time",
    "section": "3.2 Subset Analysis: 1809-1917",
    "text": "3.2 Subset Analysis: 1809-1917\nIn this segment we concentrate on the so called “long 19th century”: literary production during the years 1809-1917, when the Grand Duchy of Finland was an autonomous part of the Russian Empire.\nPublication year conversions (1809-1917)\nPublication year discarded (1809-1917)\nDownload publication time harmonized dataset (1809-1917)\n\n3.2.1 Title count per decade\nA plot depicting title counts per decade from 1809 to 1917 enriches the analysis by visually capturing the trends and fluctuations in literary output over this historical period."
  },
  {
    "objectID": "acknowledgments.html",
    "href": "acknowledgments.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "Authors:\n\n\nJulia Matveeva\nOsma Suominen\nKati Launis\nLeo Lahti\n\n\nContributors:\n\n\nJeba Akewak\nPyry Kantanen\nTeo Dallier\nElliot Gaudron-Parry\n\nThe authors wish to acknowledge CSC – IT Center for Science, Finland, for computational resources.\n\nReferences:\n\nA national public sphere? Analyzing the language, location, and form of newspapers in finland, 1771–1917  Marjanen J, Vaara V, Kanner A, Roivainen H, Mäkelä E, Lahti L & Tolonen M. Journal of European Periodical Studies 4(1), 2019 Special issue: Digital Approaches Towards Serial Publications 10.21825/jeps.v4i1.10483 | PDF \nBibliographic data science and the history of the book (c. 1500–1800) Lahti L, Marjanen J, Roivainen H & Tolonen M. Cataloging & Classification Quarterly 57(1) Routledge, 2019 Special issue. 10.1080/01639374.2018.1543747 | PDF\n\nFunders:\n\n\nResearch Council of Finland DHL-FI project\n\nAcademy of Finland website\n\nFIN-CLARIAH research infrastructure\n\nFIN-CLARIAH website"
  },
  {
    "objectID": "technical_information.html",
    "href": "technical_information.html",
    "title": "Technical information",
    "section": "",
    "text": "This document was generated with the following packages:\n\nsessionInfo()\n\nR version 4.1.2 (2021-11-01)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] fennica_0.2.9     stringi_1.8.4     purrr_1.0.2       Cairo_1.5-14     \n [5] ggplot2_3.5.1     R.utils_2.12.3    R.oo_1.27.0       R.methodsS3_1.8.2\n [9] knitr_1.49        stringr_1.5.1     tm_0.7-15         NLP_0.3-2        \n[13] dplyr_1.1.4       devtools_2.4.5    usethis_3.1.0    \n\nloaded via a namespace (and not attached):\n [1] stringdist_0.9.14 tidyselect_1.2.1  xfun_0.50         slam_0.1-55      \n [5] remotes_2.5.0     colorspace_2.1-1  vctrs_0.6.5       generics_0.1.3   \n [9] miniUI_0.1.1.1    htmltools_0.5.8.1 XML_3.99-0.18     rlang_1.1.4      \n[13] pkgbuild_1.4.5    urlchecker_1.0.1  later_1.4.1       pillar_1.10.1    \n[17] glue_1.8.0        withr_3.0.2       sessioninfo_1.2.2 lifecycle_1.0.4  \n[21] munsell_0.5.1     gtable_0.3.6      htmlwidgets_1.6.4 memoise_2.0.1    \n[25] evaluate_1.0.1    fastmap_1.2.0     httpuv_1.6.15     parallel_4.1.2   \n[29] Rcpp_1.0.13-1     xtable_1.8-4      promises_1.3.2    scales_1.3.0     \n[33] cachem_1.1.0      pkgload_1.4.0     jsonlite_1.8.9    mime_0.12        \n[37] fs_1.6.5          digest_0.6.37     shiny_1.10.0      grid_4.1.2       \n[41] cli_3.6.3         tools_4.1.2       magrittr_2.0.3    tibble_3.2.1     \n[45] profvis_0.4.0     pkgconfig_2.0.3   ellipsis_0.3.2    data.table_1.16.4\n[49] xml2_1.3.6        rmarkdown_2.29    rstudioapi_0.17.1 R6_2.5.1         \n[53] compiler_4.1.2"
  }
]