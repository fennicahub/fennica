---
title: "Language"
hide-description: false
description: ""
---

```{r}
#| include = FALSE
source("init.R")
source("language.R")
```

MARC: [041,a](https://www.loc.gov/marc/bibliographic/bd041.html)

## Description

The **polish_languages** function is designed to standardize and harmonize language information in a dataset. The process starts by isolating unique language entries, ensuring that each distinct combination of languages is processed only once, which improves efficiency and avoids redundant computations. A [MARC reference list](https://www.loc.gov/marc/languages/language_code.html) of recognized language abbreviations and names is then used to map language codes to their standardized forms. Each language entry is analyzed to identify multiple languages and to detect any unrecognized terms.

The entries are standardized by converting them to their recognized forms while eliminating duplicates and filtering out unrecognized languages. Empty cells in the dataset are marked as **NA** to indicate missing information. Once standardized, all valid languages are aggregated to create a structured data frame. This data frame includes the total number of languages in each entry, a flag **(TRUE/FALSE)** indicating whether the entry contains multiple languages (including those that are originally coded as mul = Multiple language), the cleaned and harmonized list of languages, and the primary language, which is defined as the first listed language in each entry. The result is a cleaned and standardized dataset that facilitates accurate analysis of multilingual data.

Additionally, an error list is generated, consisting of unrecognized language information and the corresponding IDs. This error list helps librarians identify mistakes in the original data and provides context to either correct the errors or explain why certain entries were discarded by the function. 

## Complete Dataset Overview

[Unique languages](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/languages_accepted.csv):  `r length(unique(unlist(strsplit(as.character(df$languages), ";"))))-1` 

[Unique primary languages](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_primary_accepted.csv): `r length(unique(df$language_primary))-1` 

`r sum(!df$multilingual & df$language_count > 0, na.rm = TRUE)` single-language entries (`r round(100 * mean(!df$multilingual & df$language_count > 0, na.rm = TRUE), 2)`%)

`r sum(df$multilingual, na.rm = TRUE)` multilingual entries , accounting for `r round(100 * mean(df$multilingual, na.rm = TRUE), 2)`% of the total. This includes entries explicitly coded as "mul" (Multiple languages) as well as those with more than one language listed for a single book.

There are `r sum(df$languages == "Undetermined",na.rm = TRUE)` single-language entries marked as only "Undetermined", coded as "und" in the dataset, accounting for (`r round(100*mean(df$languages == "Undetermined",na.rm = TRUE), 2)`%) of the total. 
 
There are `r sum(is.na(df$languages))` missing values in the dataset,accounting for (`r round(100*mean(is.na(df$languages)), 2)`%) of the total. 

[Unrecognized language](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_discarded.csv) provides details of languages that were discarded: `r sum(df$language_count == 0, na.rm = TRUE)` 
Additionally, the [Error list](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_discarded_id.csv) contains ID numbers of entries associated with these discarded languages, intended for librarian review.

[Conversions from raw to preprocessed language entries](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_conversions.csv)

New custom abbreviations can be added in [this table](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_abbreviations.csv).

[Download language harmonized dataset](https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language.csv)

## Subset Analysis: 1809-1917

[Unique languages (1809-1917)](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/languages_accepted_19.csv): `r length(unique(unlist(strsplit(as.character(df_19$languages), ";"))))-1`

[Unique primary languages  (1809-1917)](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_primary_accepted_19.csv): `r length(unique(df_19$language_primary))-1` 

`r sum(!df_19$multilingual & df_19$language_count > 0, na.rm = TRUE)` single-language entries (`r round(100 * mean(!df_19$multilingual & df_19$language_count > 0, na.rm = TRUE), 2)`%)

`r sum(df_19$multilingual, na.rm = TRUE)` multilingual entries (`r round(100 * mean(df_19$multilingual, na.rm = TRUE), 2)`%).

There are `r sum(df_19$languages == "Undetermined", na.rm = TRUE)` entries marked as "Undetermined".

There are `r sum(is.na(df_19$languages))` missing values in the dataset,accounting for (`r round(100*mean(is.na(df_19$languages)), 2)`%) of the total. 

Discarded languages: `r sum(df_19$language_count == 0, na.rm = TRUE)` 


[Download language harmonized dataset (1809-1917)](https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/language_19.csv)

### Top languages for 1809-1917

Number of titles assigned with each language (top-10). For a complete list, see [accepted languages (1809-1917)](dataTable/data_table.html?path=https://a3s.fi/swift/v1/AUTH_3c0ccb602fa24298a6fe3ae224ca022f/fennica-container/output.tables/languages_accepted_19.csv).

```{r}
#| label = "summarylang2",
#| echo = FALSE,
#| results = "asis"
x <- top(df_19, "languages")
tab <- cbind(names(x), unname(x), round(100 * unname(x/nrow(df)), 1))
colnames(tab) <- c("Language", "Entries (n)", "Fraction (%)")
kable(head(tab, 10))
```

Title count per language (including multi-language documents; note the log10 scale):

```{r}
#| label = "summarylang",
#| echo = FALSE,
#| message = FALSE,
#| warning = FALSE,
#| fig.width = 9,
#| fig.height = 7
top_plot(df_19, "languages", ntop = ntop, log10 = TRUE) + labs(y = "Entries (n)")
```


